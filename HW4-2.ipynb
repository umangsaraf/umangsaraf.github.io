{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HW4 : A visit to the movie zoo!\n",
    "\n",
    "![](https://vignette.wikia.nocookie.net/bojackhorseman/images/f/f2/HSACWDTK%3FDTKT%3FLFO%21%21.png/revision/latest?cb=20150720050503)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task\n",
    "In this homework, your task is to visualize THREE non-typical charts on anything related to your favorite **movie star!**\n",
    "This means you CANNOT use the Big 4 chart types or their close variants (i.e. Pie, Bar, Line and Scatter, Area, etc.)\n",
    "\n",
    "You are free to use any other chart type whether or not they were covered in class!\n",
    "The lecture on Visit To The Zoo is a good place to start to get ideas on what kinds of charts exist.\n",
    "\n",
    "For the data, you are free to use any data source you deem fit.\n",
    "For charting, we will NOT be constraining the technology you use. \n",
    "You are free to produce the charts in any way you would like.\n",
    "\n",
    "You will be judged on\n",
    "* Creativity\n",
    "* Presentation Quality\n",
    "* Data Quality (Did your visualization reveal something interesting?)\n",
    "\n",
    "For extra credit, you can make a fully interactive visualization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ideas for Data Collection\n",
    "\n",
    "Here, we show an example of how to collect data about Arnold Schwarzenegger!\n",
    "Do note that this is just an example of the kind of data you can collect.\n",
    "You are **NOT** constrained\n",
    "* To the same movie star (you can pick your own!)\n",
    "* To the same *kind* of data\n",
    "* To the same data sources\n",
    "* or to anything else!\n",
    "\n",
    "This assignment gives you the power to do what you like!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "from bs4 import BeautifulSoup\n",
    "import urllib.request\n",
    "import re\n",
    "import pandas as pd\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get data for Arnold Schwarzenegger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(NameSearchResult(imdb_id='nm0000216', name='Arnold Schwarzenegger'), NameSearchResult(imdb_id='nm2200639', name='Patrick Schwarzenegger'), NameSearchResult(imdb_id='nm0004569', name='Sanjay Dutt'))\n"
     ]
    }
   ],
   "source": [
    "# Get an instance of IMDb class\n",
    "imdb = ImdbFacade()\n",
    "\n",
    "# Search for Arnold Schwarzenegger\n",
    "people = imdb.search_for_name('Arnold Schwarzenegger')\n",
    "print(people)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bios\n",
      "birth_place\n",
      "date_of_birth\n",
      "filmography\n",
      "gender\n",
      "image\n",
      "imdb_id\n",
      "name\n"
     ]
    }
   ],
   "source": [
    "# Fetch information about him\n",
    "arnold = imdb.get_name(people[0].imdb_id)\n",
    "\n",
    "# What information do I have about him?\n",
    "print('\\n'.join([x for x in dir(arnold) if not x.startswith('__')]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "710\n"
     ]
    }
   ],
   "source": [
    "# How many movies does he have?\n",
    "print(len(arnold.filmography))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's fetch some more information about a movie\n",
    "movie = imdb.get_title(arnold.filmography[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "certification\n",
      "creators\n",
      "credits\n",
      "directors\n",
      "episode\n",
      "episodes\n",
      "genres\n",
      "image\n",
      "imdb_id\n",
      "plot_outline\n",
      "rating\n",
      "rating_count\n",
      "release_date\n",
      "releases\n",
      "runtime\n",
      "season\n",
      "stars\n",
      "title\n",
      "type\n",
      "writers\n",
      "year\n"
     ]
    }
   ],
   "source": [
    "# What information can I get about this movie?\n",
    "print('\\n'.join([x for x in dir(movie) if not x.startswith('__')]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tt0096708\n"
     ]
    }
   ],
   "source": [
    "print(movie.imdb_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div style=\"background-color:#FFDDDD\">\n",
       "    <h2> Warning! </h2>\n",
       "    <p> This code below is meant to be an example of what you can do. <br>\n",
       "        It is not guaranteed to work always, and will need to be tweaked!\n",
       "    </p>\n",
       "    </div>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "html = \"\"\"\n",
    "    <div style=\"background-color:#FFDDDD\">\n",
    "    <h2> Warning! </h2>\n",
    "    <p> This code below is meant to be an example of what you can do. <br>\n",
    "        It is not guaranteed to work always, and will need to be tweaked!\n",
    "    </p>\n",
    "    </div>\n",
    "\"\"\"\n",
    "display(HTML(html))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Box office numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Domestic Earnings: $38,371,200\n",
      "Total International Earnings: $40,000,000\n",
      "Weekly Domestic Earnings:\n",
      "\tOct 26-Nov 1 \t: $5,560,930\n",
      "\tNov 2-8 \t: $5,752,018\n",
      "\tNov 9-15 \t: $4,764,277\n",
      "\tNov 16-22 \t: $5,208,881\n",
      "\tNov 23-29 \t: $4,851,910\n",
      "\tNov 30-Dec 6 \t: $3,741,759\n",
      "\tDec 7-13 \t: $2,002,925\n",
      "\tDec 14-20 \t: $1,399,646\n",
      "\tDec 21-27 \t: $722,260\n",
      "\tJan 11-17 \t: $752,723\n",
      "\tJan 18-24 \t: $618,670\n"
     ]
    }
   ],
   "source": [
    "# Let's experiment with Terminator\n",
    "imdb_id = 'tt0088247'\n",
    "\n",
    "# Fetch the box office numbers\n",
    "base = 'https://www.boxofficemojo.com'\n",
    "url = base + '/title/' + imdb_id\n",
    "source = urllib.request.urlopen(url).read()\n",
    "soup = BeautifulSoup(source,'lxml')\n",
    "\n",
    "table = soup('th', text=re.compile(r'Release Group'))[0].parent.parent\n",
    "group = table.findAll('tr', recursive=False)[1].find('a').get('href')\n",
    "url = base + group\n",
    "\n",
    "# Get total earnings domestic and international\n",
    "source = urllib.request.urlopen(url).read()\n",
    "soup = BeautifulSoup(source,'lxml')\n",
    "earnings = soup('h2', text=re.compile(r'Rollout'))[0].parent.parent.findAll('div')\n",
    "domestic = earnings[1].find('span', {'class': 'money'}).get_text()\n",
    "domestic_url = earnings[1].find('a').get('href')\n",
    "international = earnings[2].find('span', {'class': 'money'}).get_text()\n",
    "\n",
    "# Get weekly domestic earnings\n",
    "url = base + domestic_url\n",
    "url = url[:url.rfind('/')] + '/weekly/'\n",
    "source = urllib.request.urlopen(url).read()\n",
    "soup = BeautifulSoup(source,'lxml')\n",
    "table = soup.find('div', {'class':'a-section imdb-scroll-table-inner'}).findAll('tr')\n",
    "weekly = []\n",
    "for tr in table[1:]:\n",
    "    date = tr.findAll('td')[0].get_text()\n",
    "    earning = tr.findAll('td')[2].get_text()\n",
    "    weekly.append((date, earning))\n",
    "\n",
    "# Print the values we've just got!\n",
    "print(\"Total Domestic Earnings: %s\" % domestic)\n",
    "print(\"Total International Earnings: %s\" % international)\n",
    "print(\"Weekly Domestic Earnings:\")\n",
    "for date, earning in weekly:\n",
    "    print(\"\\t%s \\t: %s\" % (date, earning))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imdb\n",
    "ia = imdb.IMDb()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other resources!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This assignment doesn't have a restriction on where you can look for data.\n",
    "Further, we don't mind how you collect the data, or what data you collect.\n",
    "\n",
    "Here are some additional resources for this example, and you can customize it for your own!\n",
    "* Arnold Schwarzenegger Kill Count: https://www.youtube.com/watch?v=OE6jpTaOYMU\n",
    "* Arnold Schwarzenegger Top Quotes: https://www.youtube.com/watch?v=pDxn0Xfqkgw\n",
    "\n",
    "You could think about the IMDB network as a graph, with different actors connected through movies.\n",
    "\n",
    "Some other useful libraries/ databases:\n",
    "* IMDBPy\n",
    "* http://www.omdbapi.com/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Fetch the box office numbers\n",
    "base = 'https://www.boxofficemojo.com'\n",
    "url = 'https://www.imdb.com/name/nm0000288/?ref_=tt_cl_t2#actor'\n",
    "r = requests.get(url) \n",
    "urlText = r.text\n",
    "soup = BeautifulSoup(urlText, 'html.parser')\n",
    "\n",
    "#table = soup('th', text=re.compile(r'Release Group'))[0].parent.parent\n",
    "#group = table.findAll('tr', recursive=False)[1].find('a').get('href')\n",
    "#url = base + group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_movies_actor(url):\n",
    "    \"\"\"\n",
    "    Takes in actors URL\n",
    "    Returns name of movies and there URL\n",
    "    \n",
    "    \"\"\"\n",
    "    r = requests.get(url) \n",
    "    urlText = r.text\n",
    "    soup = BeautifulSoup(urlText, 'html.parser')\n",
    "\n",
    "\n",
    "    movies1 = soup.find('div', attrs = {'class':'filmo-category-section'}).find_all('div', attrs ={'class':'filmo-row odd'})\n",
    "    movies2 = soup.find('div', attrs = {'class':'filmo-category-section'}).find_all('div', attrs ={'class':'filmo-row even'})\n",
    "\n",
    "    movie_name = {}\n",
    "    for i in movies1:\n",
    "        movie_name[i.find('b').find('a').text] = i.find('b').find('a').get('href')\n",
    "    for i in movies2:\n",
    "        movie_name[i.find('b').find('a').text] = i.find('b').find('a').get('href')\n",
    "    return movie_name\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_name = {}\n",
    "for i in movies1:\n",
    "    movie_name[i.find('b').find('a').text] = i.find('b').find('a').get('href')\n",
    "for i in movies2:\n",
    "    movie_name[i.find('b').find('a').text] = i.find('b').find('a').get('href')\n",
    "        \n",
    "\n",
    "len(movie_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Ford v Ferrari': '/title/tt1950186/',\n",
       " 'Mowgli: Legend of the Jungle': '/title/tt2388771/',\n",
       " 'The Promise': '/title/tt4776998/',\n",
       " 'Knight of Cups': '/title/tt2101383/',\n",
       " 'American Hustle': '/title/tt1800241/',\n",
       " 'The Dark Knight Rises': '/title/tt1345836/',\n",
       " 'The Fighter': '/title/tt0964517/',\n",
       " 'Terminator Salvation': '/title/tt0438488/',\n",
       " \"I'm Not There\": '/title/tt0368794/',\n",
       " 'The Prestige': '/title/tt0482571/',\n",
       " 'The New World': '/title/tt0402399/',\n",
       " 'Batman Begins': '/title/tt0372784/',\n",
       " \"Howl's Moving Castle\": '/title/tt0347149/',\n",
       " 'Equilibrium': '/title/tt0238380/',\n",
       " 'Laurel Canyon': '/title/tt0298408/',\n",
       " 'Shaft': '/title/tt0162650/',\n",
       " 'Mary, Mother of Jesus': '/title/tt0214930/',\n",
       " 'All the Little Animals': '/title/tt0120584/',\n",
       " 'Metroland': '/title/tt0119665/',\n",
       " 'The Portrait of a Lady': '/title/tt0117364/',\n",
       " 'Little Women': '/title/tt0110367/',\n",
       " 'Swing Kids': '/title/tt0108265/',\n",
       " 'A Murder of Quality': '/title/tt0102485/',\n",
       " 'Treasure Island': '/title/tt0100813/',\n",
       " 'Empire of the Sun': '/title/tt0092965/',\n",
       " 'Heart of the Country': '/title/tt0090446/',\n",
       " 'Vice': '/title/tt6266538/',\n",
       " 'Hostiles': '/title/tt5478478/',\n",
       " 'The Big Short': '/title/tt1596363/',\n",
       " 'Exodus: Gods and Kings': '/title/tt1528100/',\n",
       " 'Out of the Furnace': '/title/tt1206543/',\n",
       " 'Jin ling shi san chai': '/title/tt1410063/',\n",
       " 'Public Enemies': '/title/tt1152836/',\n",
       " 'The Dark Knight': '/title/tt0468569/',\n",
       " '3:10 to Yuma': '/title/tt0381849/',\n",
       " 'Rescue Dawn': '/title/tt0462504/',\n",
       " 'Harsh Times': '/title/tt0433387/',\n",
       " 'The Machinist': '/title/tt0361862/',\n",
       " 'Reign of Fire': '/title/tt0253556/',\n",
       " \"Captain Corelli's Mandolin\": '/title/tt0238112/',\n",
       " 'American Psycho': '/title/tt0144084/',\n",
       " \"A Midsummer Night's Dream\": '/title/tt0140379/',\n",
       " 'Velvet Goldmine': '/title/tt0120879/',\n",
       " 'The Secret Agent': '/title/tt0117582/',\n",
       " 'Pocahontas': '/title/tt0114148/',\n",
       " 'Royal Deceit': '/title/tt0110891/',\n",
       " 'Newsies': '/title/tt0104990/',\n",
       " 'The Dreamstone': '/title/tt0299286/',\n",
       " 'Henry V': '/title/tt0097499/',\n",
       " 'Mio min Mio': '/title/tt0093543/',\n",
       " 'Anastasia: The Mystery of Anna': '/title/tt0090638/'}"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['based on book',\n",
       "  'motor sports',\n",
       "  'racecar',\n",
       "  'racecar driver',\n",
       "  'based on true story',\n",
       "  '24 hours le mans race',\n",
       "  'automobile',\n",
       "  'singing in a car',\n",
       "  'englishman abroad',\n",
       "  'englishwoman abroad',\n",
       "  'american abroad',\n",
       "  'year 1966',\n",
       "  'indy 500',\n",
       "  'husband wife relationship',\n",
       "  'father son relationship',\n",
       "  'mother son relationship',\n",
       "  'boy',\n",
       "  'friendship',\n",
       "  'friend',\n",
       "  'punched in the face',\n",
       "  'fight',\n",
       "  'car racing',\n",
       "  'automobile mechanic',\n",
       "  'wrench',\n",
       "  'throwing a wrench at someone',\n",
       "  'time watch',\n",
       "  'pit stop',\n",
       "  'reference to sophia loren',\n",
       "  'reference to monica vitti',\n",
       "  'reference to steve mcqueen the actor',\n",
       "  'reference to henry ford',\n",
       "  'ford mustang',\n",
       "  'ford motor company',\n",
       "  'assembly line',\n",
       "  'automobile manufacturing',\n",
       "  'automobile designing',\n",
       "  'italy',\n",
       "  'italian',\n",
       "  'subtitled scene',\n",
       "  'subjective camera',\n",
       "  'watching tv',\n",
       "  'listening to a radio',\n",
       "  'ken miles character',\n",
       "  'rain',\n",
       "  'reckless driving',\n",
       "  'driving in the rain',\n",
       "  'car explosion',\n",
       "  'death of husband',\n",
       "  'groceries',\n",
       "  'sportswear',\n",
       "  'telephone',\n",
       "  'telephone call',\n",
       "  'ferrari',\n",
       "  'newspaper',\n",
       "  'newspaper headline',\n",
       "  'reference to fiat automobiles',\n",
       "  'based on real people',\n",
       "  'male friendship',\n",
       "  'male bonding',\n",
       "  'death of friend',\n",
       "  'death of father',\n",
       "  'reference to adolf hitler',\n",
       "  'reference to franklin d. roosevelt',\n",
       "  'reference to world war ii'],\n",
       " 'https://www.imdb.com/title/tt1950186/keywords')"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_keywords(link):\n",
    "    base_url  = 'https://www.imdb.com'\n",
    "    url = base_url + link\n",
    "    r = requests.get(url) \n",
    "    urlText = r.text\n",
    "    soup = BeautifulSoup(urlText, 'html.parser')\n",
    "    items =  soup.find_all('div', attrs={'class':'sodatext'})\n",
    "    return [i.text.strip() for i in items], url\n",
    "get_keywords('/title/tt1950186/keywords')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'4 March 2016 (USA)'"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find('a', attrs = {'title':'See more release dates'}).text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ford v Ferrari\n",
      "Mowgli: Legend of the Jungle\n",
      "The Promise\n",
      "Knight of Cups\n",
      "American Hustle\n",
      "The Dark Knight Rises\n",
      "The Fighter\n",
      "Terminator Salvation\n",
      "I'm Not There\n",
      "The Prestige\n",
      "The New World\n",
      "Batman Begins\n",
      "Howl's Moving Castle\n",
      "Equilibrium\n",
      "Laurel Canyon\n",
      "Shaft\n",
      "Mary, Mother of Jesus\n",
      "All the Little Animals\n",
      "Metroland\n",
      "The Portrait of a Lady\n",
      "Little Women\n",
      "Swing Kids\n",
      "A Murder of Quality\n",
      "Treasure Island\n",
      "Empire of the Sun\n",
      "Heart of the Country\n",
      "Vice\n",
      "Hostiles\n",
      "The Big Short\n",
      "Exodus: Gods and Kings\n",
      "Out of the Furnace\n",
      "Jin ling shi san chai\n",
      "Public Enemies\n",
      "The Dark Knight\n",
      "3:10 to Yuma\n",
      "Rescue Dawn\n",
      "Harsh Times\n",
      "The Machinist\n",
      "Reign of Fire\n",
      "Captain Corelli's Mandolin\n",
      "American Psycho\n",
      "A Midsummer Night's Dream\n",
      "Velvet Goldmine\n",
      "The Secret Agent\n",
      "Pocahontas\n",
      "Royal Deceit\n",
      "Newsies\n",
      "The Dreamstone\n",
      "Henry V\n",
      "Mio min Mio\n",
      "Anastasia: The Mystery of Anna\n"
     ]
    }
   ],
   "source": [
    "def get_keywords(link):\n",
    "    base_url  = 'https://www.imdb.com'\n",
    "    url = base_url + link\n",
    "    r = requests.get(url) \n",
    "    urlText = r.text\n",
    "    soup = BeautifulSoup(urlText, 'html.parser')\n",
    "    items =  soup.find_all('div', attrs={'class':'sodatext'})\n",
    "    return [i.text.strip() for i in items], url\n",
    "\n",
    "def get_movie_data(movie_name):\n",
    "    \"\"\"\n",
    "    Takes in dictionary with movie name and URL\n",
    "    \"\"\"\n",
    "    all_list =   []\n",
    "    for i in movie_name.keys():\n",
    "        base_url  = 'https://www.imdb.com'\n",
    "        url = base_url + movie_name[i]\n",
    "        r = requests.get(url) \n",
    "        urlText = r.text\n",
    "        soup = BeautifulSoup(urlText, 'html.parser')\n",
    "        dic = {}\n",
    "        dic['name']= i\n",
    "        if soup.find('span', attrs = {'itemprop':'ratingValue'}) != None:\n",
    "            dic['ratings'] = soup.find('span', attrs = {'itemprop':'ratingValue'}).text\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "        dic['votes'] = soup.find('span', attrs = {'itemprop':'ratingCount'}).text\n",
    "        if float(dic['votes'].replace(',', '')) < 1000:\n",
    "            continue \n",
    "        metascore = soup.find('div', attrs = {'class':'titleReviewBarItem'}).find('a').find('span')\n",
    "        if metascore != None:\n",
    "            dic['metascore'] = metascore.text\n",
    "        data_users_critics = soup.find('div', attrs = {'class':'titleReviewBarItem titleReviewbarItemBorder'}).find_all('a')\n",
    "        dic['n users'] = data_users_critics[0].text\n",
    "        if len(data_users_critics) > 1:\n",
    "            dic['n critics'] = data_users_critics[1].text\n",
    "        dic['director']  = soup.find('div', attrs = {'class':'credit_summary_item'}).find('a').text\n",
    "        link = soup.find('div', attrs = {'class':'see-more inline canwrap'}).find_all('a')[-1].get('href')\n",
    "        dic['keywords']  = get_keywords(link)\n",
    "        genres_s = soup.find_all('div', attrs = {'class':'see-more inline canwrap'})[1].find_all('a')\n",
    "        dic['genres'] = [i.text.strip() for i in genres_s]\n",
    "        dic['date'] = soup.find('a', attrs = {'title':'See more release dates'}).text.strip()\n",
    "\n",
    "        all_list.append(dic)\n",
    "    return pd.DataFrame(all_list)\n",
    "def get_movies_actor(url):\n",
    "    \"\"\"\n",
    "    Takes in actors URL\n",
    "    Returns name of movies and there URL\n",
    "    \n",
    "    \"\"\"\n",
    "    r = requests.get(url) \n",
    "    urlText = r.text\n",
    "    soup = BeautifulSoup(urlText, 'html.parser')\n",
    "\n",
    "\n",
    "    movies1 = soup.find('div', attrs = {'class':'filmo-category-section'}).find_all('div', attrs ={'class':'filmo-row odd'})\n",
    "    movies2 = soup.find('div', attrs = {'class':'filmo-category-section'}).find_all('div', attrs ={'class':'filmo-row even'})\n",
    "\n",
    "    movie_name = {}\n",
    "    for i in movies1:\n",
    "        movie_name[i.find('b').find('a').text] = i.find('b').find('a').get('href')\n",
    "    for i in movies2:\n",
    "        movie_name[i.find('b').find('a').text] = i.find('b').find('a').get('href')\n",
    "    return get_movie_data(movie_name)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_df.to_csv('movies.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "lis = movies_df['keywords'].tolist()\n",
    "dictonary = pd.Series(sum(lis, [])).value_counts().to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove(x):\n",
    "    if type(x) == str:\n",
    "        return int(x.replace(',','').split()[0])\n",
    "    else:\n",
    "        x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_df = pd.DataFrame(all_list)\n",
    "movies_df['n critics'].fillna(0, inplace=True)\n",
    "movies_df['n users'].fillna(0, inplace=True)\n",
    "\n",
    "\n",
    "movies_df['date'] = movies_df['date'].apply(lambda x:' '.join(x.split()[:-1]))\n",
    "movies_df['keywords'] = movies_df['keywords'].apply(lambda x:x[0])\n",
    "movies_df['n critics'] = movies_df['n critics'].apply(remove)\n",
    "movies_df['n users'] = movies_df['n users'].apply(remove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_m = movies_df['genres'].tolist()\n",
    "flatten = lambda list_m: [item for sublist in list_m for item in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "153"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_m_ = sum(list_m, [])\n",
    "len(list_m_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'list_m_' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-13b4746b9b78>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlist_m_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'list_m_' is not defined"
     ]
    }
   ],
   "source": [
    "list_m_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Drama        39\n",
       "Action       16\n",
       "Thriller     12\n",
       "Adventure    11\n",
       "Biography    10\n",
       "Crime         9\n",
       "Romance       9\n",
       "History       8\n",
       "Fantasy       6\n",
       "War           6\n",
       "Family        5\n",
       "Comedy        4\n",
       "Music         4\n",
       "Western       3\n",
       "Sci-Fi        3\n",
       "Mystery       2\n",
       "Sport         2\n",
       "Animation     2\n",
       "Musical       2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = pd.Series(list_m_)\n",
    "s.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Action', 'Biography', 'Drama', 'Sport'],\n",
       " ['Adventure', 'Drama', 'Fantasy'],\n",
       " ['Action', 'Adventure', 'Drama', 'History', 'War'],\n",
       " ['Drama', 'Romance'],\n",
       " ['Crime', 'Drama'],\n",
       " ['Action', 'Thriller'],\n",
       " ['Biography', 'Drama', 'Sport'],\n",
       " ['Action', 'Sci-Fi'],\n",
       " ['Biography', 'Drama', 'Music', 'Western'],\n",
       " ['Drama', 'Mystery', 'Sci-Fi', 'Thriller'],\n",
       " ['Biography', 'Drama', 'History', 'Romance'],\n",
       " ['Action', 'Adventure'],\n",
       " ['Animation', 'Adventure', 'Family', 'Fantasy'],\n",
       " ['Action', 'Drama', 'Sci-Fi', 'Thriller'],\n",
       " ['Drama'],\n",
       " ['Action', 'Crime', 'Thriller'],\n",
       " ['Drama'],\n",
       " ['Adventure', 'Drama', 'Thriller'],\n",
       " ['Comedy', 'Drama'],\n",
       " ['Drama', 'Romance'],\n",
       " ['Drama', 'Family', 'Romance'],\n",
       " ['Drama', 'Music'],\n",
       " ['Action', 'Adventure', 'Crime'],\n",
       " ['Drama', 'History', 'War'],\n",
       " ['Biography', 'Comedy', 'Drama'],\n",
       " ['Drama', 'Western'],\n",
       " ['Biography', 'Comedy', 'Drama', 'History'],\n",
       " ['Action', 'Drama', 'Fantasy'],\n",
       " ['Action', 'Crime', 'Drama', 'Thriller'],\n",
       " ['Drama', 'History', 'Romance', 'War'],\n",
       " ['Biography', 'Crime', 'Drama', 'History'],\n",
       " ['Action', 'Crime', 'Drama', 'Thriller'],\n",
       " ['Action', 'Crime', 'Drama', 'Western'],\n",
       " ['Action', 'Adventure', 'Biography', 'Drama', 'Thriller', 'War'],\n",
       " ['Action', 'Crime', 'Drama', 'Thriller'],\n",
       " ['Drama', 'Thriller'],\n",
       " ['Action', 'Adventure', 'Fantasy', 'Thriller'],\n",
       " ['Drama', 'Music', 'Romance', 'War'],\n",
       " ['Crime', 'Drama'],\n",
       " ['Comedy', 'Fantasy', 'Romance'],\n",
       " ['Drama', 'Music'],\n",
       " ['Drama', 'Thriller'],\n",
       " ['Animation', 'Adventure', 'Drama', 'Family', 'Musical', 'Romance'],\n",
       " ['Adventure', 'Drama'],\n",
       " ['Drama', 'Family', 'History', 'Musical'],\n",
       " ['Action', 'Biography', 'Drama', 'History', 'Romance', 'War'],\n",
       " ['Adventure', 'Family', 'Fantasy'],\n",
       " ['Biography', 'Drama', 'Mystery']]"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "only_fi[list_m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(48, 10)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('movies.csv')\n",
    "df.drop('Unnamed: 0', axis =1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
